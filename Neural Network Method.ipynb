{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin the preprocessing ,we use the latest three years exchange rate data to build our data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot  \n",
    "from math import sqrt  \n",
    "JPY_temp=pd.read_csv('E:\\\\JPY.csv')\n",
    "JPY=JPY_temp.iloc[:,[1,2,3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use the function below to transform the exchange rate into the sequence of fluctuation."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define x as fluctuation sequence of the exchange rate at date t-5,t-4,t-3,t-2,t-1, and y is the fluctuation sequence of the exchange rate at date t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x= (586, 5)\n",
      "y= (586, 1)\n"
     ]
    }
   ],
   "source": [
    "x1=JPY.iloc[1:-4,1].values\n",
    "x2=JPY.iloc[2:-3,1].values\n",
    "x3=JPY.iloc[3:-2,1].values\n",
    "x4=JPY.iloc[4:-1,1].values\n",
    "x5=JPY.iloc[5:,1].values\n",
    "\n",
    "x=np.stack((x1,x2,x3,x4,x5),axis=1)\n",
    "x=x[:-1]\n",
    "y=JPY.iloc[6:,1].values.reshape(-1,1)\n",
    "\n",
    "\n",
    "print('x=',x.shape)\n",
    "print('y=',y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the samples into training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: [[-0.39  -0.59  -0.83  -0.39   0.51 ]\n",
      " [-0.59  -0.83  -0.39   0.51  -0.12 ]\n",
      " [-0.83  -0.39   0.51  -0.12   0.03 ]\n",
      " ...\n",
      " [-0.48  -0.765 -0.555  0.68  -0.075]\n",
      " [-0.765 -0.555  0.68  -0.075  1.515]\n",
      " [-0.555  0.68  -0.075  1.515 -0.415]]\n",
      "x_test: [[ 0.68  -0.075  1.515 -0.415 -0.15 ]\n",
      " [-0.075  1.515 -0.415 -0.15  -0.385]\n",
      " [ 1.515 -0.415 -0.15  -0.385  0.705]\n",
      " [-0.415 -0.15  -0.385  0.705  0.17 ]\n",
      " [-0.15  -0.385  0.705  0.17   0.61 ]\n",
      " [-0.385  0.705  0.17   0.61  -0.46 ]\n",
      " [ 0.705  0.17   0.61  -0.46  -0.145]]\n",
      "y_train: [[-0.12 ]\n",
      " [ 0.03 ]\n",
      " [ 0.39 ]\n",
      " [-1.1  ]\n",
      " [ 0.36 ]\n",
      " [ 0.3  ]\n",
      " [-0.67 ]\n",
      " [ 0.76 ]\n",
      " [ 1.04 ]\n",
      " [-0.45 ]\n",
      " [ 0.11 ]\n",
      " [ 0.28 ]\n",
      " [ 0.13 ]\n",
      " [ 2.3  ]\n",
      " [-0.14 ]\n",
      " [-1.05 ]\n",
      " [-2.08 ]\n",
      " [-1.09 ]\n",
      " [ 0.07 ]\n",
      " [-0.99 ]\n",
      " [-0.7  ]\n",
      " [-1.8  ]\n",
      " [-0.92 ]\n",
      " [ 0.78 ]\n",
      " [ 1.38 ]\n",
      " [-0.5  ]\n",
      " [ 0.   ]\n",
      " [-0.83 ]\n",
      " [-0.7  ]\n",
      " [ 0.36 ]\n",
      " [-0.83 ]\n",
      " [ 0.08 ]\n",
      " [ 0.81 ]\n",
      " [ 1.01 ]\n",
      " [-1.3  ]\n",
      " [ 1.3  ]\n",
      " [-0.52 ]\n",
      " [ 0.22 ]\n",
      " [ 0.09 ]\n",
      " [-0.32 ]\n",
      " [-0.88 ]\n",
      " [ 0.77 ]\n",
      " [-0.13 ]\n",
      " [ 0.62 ]\n",
      " [-0.01 ]\n",
      " [-0.68 ]\n",
      " [-0.46 ]\n",
      " [-1.25 ]\n",
      " [ 0.1  ]\n",
      " [ 0.43 ]\n",
      " [ 0.4  ]\n",
      " [ 0.03 ]\n",
      " [ 0.42 ]\n",
      " [ 0.24 ]\n",
      " [ 0.33 ]\n",
      " [-0.67 ]\n",
      " [-0.27 ]\n",
      " [ 0.09 ]\n",
      " [-0.89 ]\n",
      " [-0.34 ]\n",
      " [-0.97 ]\n",
      " [-0.93 ]\n",
      " [-1.14 ]\n",
      " [-0.18 ]\n",
      " [-0.12 ]\n",
      " [ 0.62 ]\n",
      " [ 0.69 ]\n",
      " [ 0.12 ]\n",
      " [-0.65 ]\n",
      " [ 0.11 ]\n",
      " [ 0.42 ]\n",
      " [ 0.47 ]\n",
      " [-0.32 ]\n",
      " [ 2.16 ]\n",
      " [-0.39 ]\n",
      " [ 0.09 ]\n",
      " [ 0.19 ]\n",
      " [-3.36 ]\n",
      " [-1.83 ]\n",
      " [ 0.11 ]\n",
      " [ 0.57 ]\n",
      " [ 0.07 ]\n",
      " [ 0.23 ]\n",
      " [-0.17 ]\n",
      " [ 1.36 ]\n",
      " [ 0.89 ]\n",
      " [-0.86 ]\n",
      " [ 0.57 ]\n",
      " [-0.42 ]\n",
      " [ 0.42 ]\n",
      " [ 0.08 ]\n",
      " [ 1.05 ]\n",
      " [-0.23 ]\n",
      " [ 0.15 ]\n",
      " [-0.86 ]\n",
      " [ 0.72 ]\n",
      " [ 0.21 ]\n",
      " [-0.43 ]\n",
      " [ 0.47 ]\n",
      " [ 0.92 ]\n",
      " [-0.41 ]\n",
      " [-1.24 ]\n",
      " [-0.65 ]\n",
      " [-2.3  ]\n",
      " [ 1.01 ]\n",
      " [-0.21 ]\n",
      " [-0.47 ]\n",
      " [ 0.1  ]\n",
      " [-0.05 ]\n",
      " [-0.8  ]\n",
      " [-0.11 ]\n",
      " [-0.01 ]\n",
      " [-1.68 ]\n",
      " [-0.2  ]\n",
      " [-0.14 ]\n",
      " [ 0.8  ]\n",
      " [ 0.06 ]\n",
      " [ 1.74 ]\n",
      " [-4.38 ]\n",
      " [-0.3  ]\n",
      " [ 0.82 ]\n",
      " [ 0.19 ]\n",
      " [ 0.38 ]\n",
      " [-0.76 ]\n",
      " [ 0.02 ]\n",
      " [-0.83 ]\n",
      " [-0.33 ]\n",
      " [-0.63 ]\n",
      " [-0.25 ]\n",
      " [ 2.26 ]\n",
      " [ 1.98 ]\n",
      " [-0.38 ]\n",
      " [ 0.97 ]\n",
      " [-0.68 ]\n",
      " [ 1.49 ]\n",
      " [-0.09 ]\n",
      " [ 1.15 ]\n",
      " [-1.05 ]\n",
      " [ 0.   ]\n",
      " [-0.33 ]\n",
      " [-1.07 ]\n",
      " [ 0.53 ]\n",
      " [ 0.01 ]\n",
      " [-3.26 ]\n",
      " [ 0.31 ]\n",
      " [-1.43 ]\n",
      " [ 0.35 ]\n",
      " [-0.09 ]\n",
      " [ 0.65 ]\n",
      " [ 0.62 ]\n",
      " [-0.59 ]\n",
      " [-0.68 ]\n",
      " [ 0.74 ]\n",
      " [-0.66 ]\n",
      " [ 0.01 ]\n",
      " [-1.   ]\n",
      " [-0.04 ]\n",
      " [-0.3  ]\n",
      " [ 0.29 ]\n",
      " [ 0.1  ]\n",
      " [-0.12 ]\n",
      " [ 0.27 ]\n",
      " [ 0.08 ]\n",
      " [ 1.27 ]\n",
      " [ 0.09 ]\n",
      " [ 1.09 ]\n",
      " [ 0.32 ]\n",
      " [-0.09 ]\n",
      " [ 0.69 ]\n",
      " [-0.49 ]\n",
      " [-1.36 ]\n",
      " [-0.38 ]\n",
      " [ 0.7  ]\n",
      " [ 0.29 ]\n",
      " [-0.74 ]\n",
      " [ 0.6  ]\n",
      " [-0.16 ]\n",
      " [-0.31 ]\n",
      " [ 0.21 ]\n",
      " [-0.39 ]\n",
      " [-0.16 ]\n",
      " [-1.29 ]\n",
      " [ 0.36 ]\n",
      " [ 0.26 ]\n",
      " [-0.75 ]\n",
      " [ 0.1  ]\n",
      " [ 0.33 ]\n",
      " [ 0.35 ]\n",
      " [ 0.24 ]\n",
      " [ 0.33 ]\n",
      " [ 1.25 ]\n",
      " [ 0.6  ]\n",
      " [ 0.48 ]\n",
      " [-1.09 ]\n",
      " [ 0.76 ]\n",
      " [-0.11 ]\n",
      " [ 0.71 ]\n",
      " [-0.59 ]\n",
      " [ 0.46 ]\n",
      " [-0.28 ]\n",
      " [ 0.02 ]\n",
      " [-0.48 ]\n",
      " [ 0.58 ]\n",
      " [-0.16 ]\n",
      " [ 0.42 ]\n",
      " [-0.01 ]\n",
      " [ 0.26 ]\n",
      " [ 0.76 ]\n",
      " [-0.57 ]\n",
      " [ 0.09 ]\n",
      " [-0.73 ]\n",
      " [-0.68 ]\n",
      " [-0.38 ]\n",
      " [ 0.13 ]\n",
      " [ 1.41 ]\n",
      " [ 0.61 ]\n",
      " [ 0.57 ]\n",
      " [ 1.12 ]\n",
      " [-0.18 ]\n",
      " [ 1.805]\n",
      " [ 0.775]\n",
      " [-0.11 ]\n",
      " [ 1.045]\n",
      " [ 0.725]\n",
      " [-0.05 ]\n",
      " [ 0.34 ]\n",
      " [ 1.35 ]\n",
      " [ 0.9  ]\n",
      " [-0.19 ]\n",
      " [-1.3  ]\n",
      " [ 0.46 ]\n",
      " [ 2.085]\n",
      " [-0.36 ]\n",
      " [-0.58 ]\n",
      " [ 0.33 ]\n",
      " [ 0.165]\n",
      " [-0.26 ]\n",
      " [ 0.27 ]\n",
      " [ 1.31 ]\n",
      " [-0.31 ]\n",
      " [ 0.18 ]\n",
      " [ 1.84 ]\n",
      " [ 1.12 ]\n",
      " [-0.23 ]\n",
      " [-0.87 ]\n",
      " [ 0.805]\n",
      " [-0.305]\n",
      " [-0.03 ]\n",
      " [-0.265]\n",
      " [-0.18 ]\n",
      " [ 0.345]\n",
      " [-0.19 ]\n",
      " [-0.7  ]\n",
      " [ 0.47 ]\n",
      " [ 0.58 ]\n",
      " [ 0.17 ]\n",
      " [-0.51 ]\n",
      " [-1.88 ]\n",
      " [ 1.62 ]\n",
      " [-0.945]\n",
      " [-0.275]\n",
      " [-0.365]\n",
      " [-0.675]\n",
      " [-0.235]\n",
      " [-0.305]\n",
      " [-1.58 ]\n",
      " [ 2.03 ]\n",
      " [ 0.225]\n",
      " [-0.34 ]\n",
      " [-1.81 ]\n",
      " [ 1.07 ]\n",
      " [-0.515]\n",
      " [ 1.25 ]\n",
      " [ 0.55 ]\n",
      " [-1.28 ]\n",
      " [-0.985]\n",
      " [ 0.445]\n",
      " [-0.44 ]\n",
      " [-0.22 ]\n",
      " [-0.86 ]\n",
      " [ 0.66 ]\n",
      " [-0.455]\n",
      " [ 1.305]\n",
      " [-0.03 ]\n",
      " [ 0.54 ]\n",
      " [ 0.5  ]\n",
      " [-0.1  ]\n",
      " [-0.9  ]\n",
      " [-0.44 ]\n",
      " [ 0.28 ]\n",
      " [ 0.6  ]\n",
      " [-0.39 ]\n",
      " [-0.69 ]\n",
      " [-0.49 ]\n",
      " [ 0.56 ]\n",
      " [ 0.09 ]\n",
      " [ 0.96 ]\n",
      " [ 0.68 ]\n",
      " [-0.38 ]\n",
      " [-0.14 ]\n",
      " [ 0.1  ]\n",
      " [ 0.375]\n",
      " [ 0.585]\n",
      " [-0.18 ]\n",
      " [ 0.08 ]\n",
      " [-0.105]\n",
      " [-1.355]\n",
      " [-0.085]\n",
      " [-0.615]\n",
      " [-0.14 ]\n",
      " [-0.835]\n",
      " [-0.55 ]\n",
      " [-0.235]\n",
      " [ 0.42 ]\n",
      " [-0.68 ]\n",
      " [ 0.46 ]\n",
      " [-0.085]\n",
      " [ 0.88 ]\n",
      " [-0.535]\n",
      " [-0.495]\n",
      " [-0.165]\n",
      " [-0.02 ]\n",
      " [ 0.1  ]\n",
      " [ 0.265]\n",
      " [-0.145]\n",
      " [-1.32 ]\n",
      " [-0.57 ]\n",
      " [ 0.05 ]\n",
      " [-0.46 ]\n",
      " [ 0.28 ]\n",
      " [-0.49 ]\n",
      " [ 0.43 ]\n",
      " [ 0.46 ]\n",
      " [-0.24 ]\n",
      " [ 0.695]\n",
      " [ 1.34 ]\n",
      " [-0.04 ]\n",
      " [ 0.185]\n",
      " [ 0.28 ]\n",
      " [ 0.315]\n",
      " [ 0.14 ]\n",
      " [ 0.765]\n",
      " [-0.28 ]\n",
      " [ 0.24 ]\n",
      " [ 0.54 ]\n",
      " [ 0.735]\n",
      " [ 0.295]\n",
      " [-0.41 ]\n",
      " [-0.52 ]\n",
      " [ 0.44 ]\n",
      " [-0.66 ]\n",
      " [-2.305]\n",
      " [ 0.665]\n",
      " [-0.23 ]\n",
      " [ 0.03 ]\n",
      " [ 0.505]\n",
      " [-0.305]\n",
      " [ 0.34 ]\n",
      " [-0.495]\n",
      " [-0.07 ]\n",
      " [-0.415]\n",
      " [-0.08 ]\n",
      " [ 0.6  ]\n",
      " [-0.985]\n",
      " [ 0.08 ]\n",
      " [-1.06 ]\n",
      " [ 0.41 ]\n",
      " [ 0.195]\n",
      " [ 0.32 ]\n",
      " [-0.385]\n",
      " [ 0.115]\n",
      " [-0.485]\n",
      " [ 1.37 ]\n",
      " [-0.06 ]\n",
      " [ 0.64 ]\n",
      " [-0.065]\n",
      " [-0.09 ]\n",
      " [-0.045]\n",
      " [-0.045]\n",
      " [ 0.61 ]\n",
      " [ 0.455]\n",
      " [-0.045]\n",
      " [-0.13 ]\n",
      " [ 0.215]\n",
      " [ 0.985]\n",
      " [-0.08 ]\n",
      " [-0.02 ]\n",
      " [-0.06 ]\n",
      " [ 0.695]\n",
      " [ 0.145]\n",
      " [-0.105]\n",
      " [-0.775]\n",
      " [ 0.12 ]\n",
      " [-0.765]\n",
      " [ 0.095]\n",
      " [-0.55 ]\n",
      " [-0.105]\n",
      " [-0.06 ]\n",
      " [-0.755]\n",
      " [-0.05 ]\n",
      " [ 0.785]\n",
      " [-0.7  ]\n",
      " [ 0.065]\n",
      " [-0.565]\n",
      " [-0.435]\n",
      " [ 0.115]\n",
      " [ 0.37 ]\n",
      " [-0.685]\n",
      " [ 0.645]\n",
      " [ 0.05 ]\n",
      " [-0.32 ]\n",
      " [-0.36 ]\n",
      " [-0.86 ]\n",
      " [-0.005]\n",
      " [ 0.43 ]\n",
      " [ 1.04 ]\n",
      " [-0.48 ]\n",
      " [-0.62 ]\n",
      " [-0.35 ]\n",
      " [-0.25 ]\n",
      " [ 0.605]\n",
      " [-0.545]\n",
      " [ 0.52 ]\n",
      " [-0.21 ]\n",
      " [-0.08 ]\n",
      " [ 0.49 ]\n",
      " [ 0.495]\n",
      " [-0.275]\n",
      " [ 0.275]\n",
      " [-0.53 ]\n",
      " [-0.905]\n",
      " [ 0.41 ]\n",
      " [-0.755]\n",
      " [-0.63 ]\n",
      " [ 1.55 ]\n",
      " [ 0.775]\n",
      " [ 0.33 ]\n",
      " [-0.245]\n",
      " [ 0.58 ]\n",
      " [ 0.74 ]\n",
      " [ 0.04 ]\n",
      " [ 0.58 ]\n",
      " [ 0.295]\n",
      " [-0.49 ]\n",
      " [-0.26 ]\n",
      " [ 0.5  ]\n",
      " [ 0.59 ]\n",
      " [-0.47 ]\n",
      " [ 0.165]\n",
      " [ 0.245]\n",
      " [ 0.085]\n",
      " [-0.095]\n",
      " [ 0.075]\n",
      " [-0.175]\n",
      " [ 0.035]\n",
      " [-0.24 ]\n",
      " [ 0.045]\n",
      " [-0.205]\n",
      " [-0.445]\n",
      " [ 0.345]\n",
      " [ 0.02 ]\n",
      " [ 0.72 ]\n",
      " [-0.38 ]\n",
      " [ 0.955]\n",
      " [-0.075]\n",
      " [ 0.485]\n",
      " [-0.165]\n",
      " [ 0.245]\n",
      " [-0.32 ]\n",
      " [-0.5  ]\n",
      " [ 0.475]\n",
      " [ 0.54 ]\n",
      " [-0.115]\n",
      " [-0.01 ]\n",
      " [-0.29 ]\n",
      " [ 0.175]\n",
      " [-0.135]\n",
      " [-0.46 ]\n",
      " [ 0.18 ]\n",
      " [ 0.1  ]\n",
      " [-0.18 ]\n",
      " [-0.58 ]\n",
      " [ 0.16 ]\n",
      " [-0.895]\n",
      " [ 0.485]\n",
      " [-0.18 ]\n",
      " [-1.23 ]\n",
      " [ 0.015]\n",
      " [ 0.31 ]\n",
      " [-0.425]\n",
      " [ 0.375]\n",
      " [ 0.44 ]\n",
      " [ 0.605]\n",
      " [-0.335]\n",
      " [ 0.21 ]\n",
      " [ 0.18 ]\n",
      " [-0.3  ]\n",
      " [ 0.8  ]\n",
      " [ 0.38 ]\n",
      " [ 0.095]\n",
      " [-0.01 ]\n",
      " [-1.005]\n",
      " [-0.14 ]\n",
      " [ 0.21 ]\n",
      " [-0.065]\n",
      " [ 0.335]\n",
      " [ 0.5  ]\n",
      " [-0.06 ]\n",
      " [-0.035]\n",
      " [ 0.   ]\n",
      " [-0.065]\n",
      " [ 0.115]\n",
      " [-0.475]\n",
      " [-0.175]\n",
      " [-0.015]\n",
      " [-0.39 ]\n",
      " [ 0.215]\n",
      " [ 0.23 ]\n",
      " [ 0.33 ]\n",
      " [ 0.02 ]\n",
      " [-0.44 ]\n",
      " [-1.21 ]\n",
      " [-0.15 ]\n",
      " [-0.27 ]\n",
      " [-0.48 ]\n",
      " [-0.06 ]\n",
      " [ 0.84 ]\n",
      " [-0.22 ]\n",
      " [-0.3  ]\n",
      " [ 0.14 ]\n",
      " [-0.625]\n",
      " [-1.08 ]\n",
      " [ 0.165]\n",
      " [-0.76 ]\n",
      " [ 0.335]\n",
      " [-0.18 ]\n",
      " [ 0.395]\n",
      " [ 0.22 ]\n",
      " [ 0.77 ]\n",
      " [-1.05 ]\n",
      " [ 0.435]\n",
      " [-0.21 ]\n",
      " [-0.6  ]\n",
      " [ 0.055]\n",
      " [-0.15 ]\n",
      " [-0.835]\n",
      " [-0.81 ]\n",
      " [-0.86 ]\n",
      " [ 0.135]\n",
      " [ 0.32 ]\n",
      " [ 0.725]\n",
      " [ 0.445]\n",
      " [-1.02 ]\n",
      " [ 0.135]\n",
      " [ 0.08 ]\n",
      " [ 0.365]\n",
      " [-0.655]\n",
      " [-0.435]\n",
      " [-0.49 ]\n",
      " [ 0.45 ]\n",
      " [-0.09 ]\n",
      " [-0.045]\n",
      " [ 0.14 ]\n",
      " [ 0.595]\n",
      " [-0.385]\n",
      " [ 0.155]\n",
      " [-0.24 ]\n",
      " [ 0.005]\n",
      " [-0.335]\n",
      " [ 0.085]\n",
      " [ 0.445]\n",
      " [-0.48 ]\n",
      " [-0.765]\n",
      " [-0.555]\n",
      " [ 0.68 ]\n",
      " [-0.075]\n",
      " [ 1.515]\n",
      " [-0.415]\n",
      " [-0.15 ]]\n",
      "y_test: [[-0.385]\n",
      " [ 0.705]\n",
      " [ 0.17 ]\n",
      " [ 0.61 ]\n",
      " [-0.46 ]\n",
      " [-0.145]\n",
      " [ 0.415]]\n"
     ]
    }
   ],
   "source": [
    "t=7\n",
    "\n",
    "y=y.reshape(-1,1)\n",
    "x_train = x[:-t]\n",
    "x_test = x[-t:]\n",
    "y_train = y[:-t]\n",
    "y_test = y[-t:]\n",
    "print('x_train:',x_train)\n",
    "print('x_test:',x_test)\n",
    "print('y_train:',y_train)\n",
    "print('y_test:',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler=preprocessing.MinMaxScaler()\n",
    "\n",
    "x_train= min_max_scaler.fit_transform(x_train)\n",
    "x_test= min_max_scaler.fit_transform(x_test)\n",
    "\n",
    "y_train=min_max_scaler.fit_transform(y_train)\n",
    "y_test= min_max_scaler.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization:\n",
      "x_train: [[0.59730539 0.56736527 0.53143713 0.59730539 0.73203593]\n",
      " [0.56736527 0.53143713 0.59730539 0.73203593 0.63772455]\n",
      " [0.53143713 0.59730539 0.73203593 0.63772455 0.66017964]\n",
      " ...\n",
      " [0.58383234 0.54116766 0.57260479 0.75748503 0.64446108]\n",
      " [0.54116766 0.57260479 0.75748503 0.64446108 0.88248503]\n",
      " [0.57260479 0.75748503 0.64446108 0.88248503 0.59356287]]\n",
      "x_test: [[0.56735751 0.1761658  1.         0.03862661 0.26609442]\n",
      " [0.1761658  1.         0.         0.26609442 0.06437768]\n",
      " [1.         0.         0.1373057  0.06437768 1.        ]\n",
      " [0.         0.1373057  0.01554404 1.         0.54077253]\n",
      " [0.1373057  0.01554404 0.58031088 0.54077253 0.91845494]\n",
      " [0.01554404 0.58031088 0.30310881 0.91845494 0.        ]\n",
      " [0.58031088 0.30310881 0.53108808 0.         0.27038627]]\n",
      "y_train: [[0.63772455]\n",
      " [0.66017964]\n",
      " [0.71407186]\n",
      " [0.49101796]\n",
      " [0.70958084]\n",
      " [0.7005988 ]\n",
      " [0.55538922]\n",
      " [0.76946108]\n",
      " [0.81137725]\n",
      " [0.58832335]\n",
      " [0.67215569]\n",
      " [0.69760479]\n",
      " [0.6751497 ]\n",
      " [1.        ]\n",
      " [0.63473054]\n",
      " [0.49850299]\n",
      " [0.34431138]\n",
      " [0.49251497]\n",
      " [0.66616766]\n",
      " [0.50748503]\n",
      " [0.5508982 ]\n",
      " [0.38622754]\n",
      " [0.51796407]\n",
      " [0.77245509]\n",
      " [0.86227545]\n",
      " [0.58083832]\n",
      " [0.65568862]\n",
      " [0.53143713]\n",
      " [0.5508982 ]\n",
      " [0.70958084]\n",
      " [0.53143713]\n",
      " [0.66766467]\n",
      " [0.77694611]\n",
      " [0.80688623]\n",
      " [0.46107784]\n",
      " [0.8502994 ]\n",
      " [0.57784431]\n",
      " [0.68862275]\n",
      " [0.66916168]\n",
      " [0.60778443]\n",
      " [0.5239521 ]\n",
      " [0.77095808]\n",
      " [0.63622754]\n",
      " [0.74850299]\n",
      " [0.65419162]\n",
      " [0.55389222]\n",
      " [0.58682635]\n",
      " [0.46856287]\n",
      " [0.67065868]\n",
      " [0.72005988]\n",
      " [0.71556886]\n",
      " [0.66017964]\n",
      " [0.71856287]\n",
      " [0.69161677]\n",
      " [0.70508982]\n",
      " [0.55538922]\n",
      " [0.61526946]\n",
      " [0.66916168]\n",
      " [0.52245509]\n",
      " [0.60479042]\n",
      " [0.51047904]\n",
      " [0.51646707]\n",
      " [0.48502994]\n",
      " [0.62874251]\n",
      " [0.63772455]\n",
      " [0.74850299]\n",
      " [0.75898204]\n",
      " [0.67365269]\n",
      " [0.55838323]\n",
      " [0.67215569]\n",
      " [0.71856287]\n",
      " [0.7260479 ]\n",
      " [0.60778443]\n",
      " [0.97904192]\n",
      " [0.59730539]\n",
      " [0.66916168]\n",
      " [0.68413174]\n",
      " [0.15269461]\n",
      " [0.38173653]\n",
      " [0.67215569]\n",
      " [0.74101796]\n",
      " [0.66616766]\n",
      " [0.69011976]\n",
      " [0.63023952]\n",
      " [0.85928144]\n",
      " [0.78892216]\n",
      " [0.52694611]\n",
      " [0.74101796]\n",
      " [0.59281437]\n",
      " [0.71856287]\n",
      " [0.66766467]\n",
      " [0.81287425]\n",
      " [0.62125749]\n",
      " [0.67814371]\n",
      " [0.52694611]\n",
      " [0.76347305]\n",
      " [0.68712575]\n",
      " [0.59131737]\n",
      " [0.7260479 ]\n",
      " [0.79341317]\n",
      " [0.59431138]\n",
      " [0.47005988]\n",
      " [0.55838323]\n",
      " [0.31137725]\n",
      " [0.80688623]\n",
      " [0.6242515 ]\n",
      " [0.58532934]\n",
      " [0.67065868]\n",
      " [0.64820359]\n",
      " [0.53592814]\n",
      " [0.63922156]\n",
      " [0.65419162]\n",
      " [0.40419162]\n",
      " [0.6257485 ]\n",
      " [0.63473054]\n",
      " [0.7754491 ]\n",
      " [0.66467066]\n",
      " [0.91616766]\n",
      " [0.        ]\n",
      " [0.61077844]\n",
      " [0.77844311]\n",
      " [0.68413174]\n",
      " [0.71257485]\n",
      " [0.54191617]\n",
      " [0.65868263]\n",
      " [0.53143713]\n",
      " [0.60628743]\n",
      " [0.56137725]\n",
      " [0.61826347]\n",
      " [0.99401198]\n",
      " [0.95209581]\n",
      " [0.5988024 ]\n",
      " [0.8008982 ]\n",
      " [0.55389222]\n",
      " [0.87874251]\n",
      " [0.64221557]\n",
      " [0.82784431]\n",
      " [0.49850299]\n",
      " [0.65568862]\n",
      " [0.60628743]\n",
      " [0.49550898]\n",
      " [0.73502994]\n",
      " [0.65718563]\n",
      " [0.16766467]\n",
      " [0.70209581]\n",
      " [0.44161677]\n",
      " [0.70808383]\n",
      " [0.64221557]\n",
      " [0.75299401]\n",
      " [0.74850299]\n",
      " [0.56736527]\n",
      " [0.55389222]\n",
      " [0.76646707]\n",
      " [0.55688623]\n",
      " [0.65718563]\n",
      " [0.50598802]\n",
      " [0.6497006 ]\n",
      " [0.61077844]\n",
      " [0.6991018 ]\n",
      " [0.67065868]\n",
      " [0.63772455]\n",
      " [0.69610778]\n",
      " [0.66766467]\n",
      " [0.84580838]\n",
      " [0.66916168]\n",
      " [0.81886228]\n",
      " [0.70359281]\n",
      " [0.64221557]\n",
      " [0.75898204]\n",
      " [0.58233533]\n",
      " [0.45209581]\n",
      " [0.5988024 ]\n",
      " [0.76047904]\n",
      " [0.6991018 ]\n",
      " [0.54491018]\n",
      " [0.74550898]\n",
      " [0.63173653]\n",
      " [0.60928144]\n",
      " [0.68712575]\n",
      " [0.59730539]\n",
      " [0.63173653]\n",
      " [0.46257485]\n",
      " [0.70958084]\n",
      " [0.69461078]\n",
      " [0.54341317]\n",
      " [0.67065868]\n",
      " [0.70508982]\n",
      " [0.70808383]\n",
      " [0.69161677]\n",
      " [0.70508982]\n",
      " [0.84281437]\n",
      " [0.74550898]\n",
      " [0.72754491]\n",
      " [0.49251497]\n",
      " [0.76946108]\n",
      " [0.63922156]\n",
      " [0.76197605]\n",
      " [0.56736527]\n",
      " [0.7245509 ]\n",
      " [0.61377246]\n",
      " [0.65868263]\n",
      " [0.58383234]\n",
      " [0.74251497]\n",
      " [0.63173653]\n",
      " [0.71856287]\n",
      " [0.65419162]\n",
      " [0.69461078]\n",
      " [0.76946108]\n",
      " [0.57035928]\n",
      " [0.66916168]\n",
      " [0.54640719]\n",
      " [0.55389222]\n",
      " [0.5988024 ]\n",
      " [0.6751497 ]\n",
      " [0.86676647]\n",
      " [0.74700599]\n",
      " [0.74101796]\n",
      " [0.82335329]\n",
      " [0.62874251]\n",
      " [0.9258982 ]\n",
      " [0.77170659]\n",
      " [0.63922156]\n",
      " [0.81212575]\n",
      " [0.76422156]\n",
      " [0.64820359]\n",
      " [0.70658683]\n",
      " [0.85778443]\n",
      " [0.79041916]\n",
      " [0.62724551]\n",
      " [0.46107784]\n",
      " [0.7245509 ]\n",
      " [0.96781437]\n",
      " [0.60179641]\n",
      " [0.56886228]\n",
      " [0.70508982]\n",
      " [0.68038922]\n",
      " [0.61676647]\n",
      " [0.69610778]\n",
      " [0.85179641]\n",
      " [0.60928144]\n",
      " [0.68263473]\n",
      " [0.93113772]\n",
      " [0.82335329]\n",
      " [0.62125749]\n",
      " [0.5254491 ]\n",
      " [0.7761976 ]\n",
      " [0.61002994]\n",
      " [0.6511976 ]\n",
      " [0.61601796]\n",
      " [0.62874251]\n",
      " [0.70733533]\n",
      " [0.62724551]\n",
      " [0.5508982 ]\n",
      " [0.7260479 ]\n",
      " [0.74251497]\n",
      " [0.68113772]\n",
      " [0.57934132]\n",
      " [0.3742515 ]\n",
      " [0.89820359]\n",
      " [0.51422156]\n",
      " [0.61452096]\n",
      " [0.6010479 ]\n",
      " [0.55464072]\n",
      " [0.62050898]\n",
      " [0.61002994]\n",
      " [0.41916168]\n",
      " [0.95958084]\n",
      " [0.68937126]\n",
      " [0.60479042]\n",
      " [0.38473054]\n",
      " [0.81586826]\n",
      " [0.57859281]\n",
      " [0.84281437]\n",
      " [0.73802395]\n",
      " [0.46407186]\n",
      " [0.50823353]\n",
      " [0.72230539]\n",
      " [0.58982036]\n",
      " [0.62275449]\n",
      " [0.52694611]\n",
      " [0.75449102]\n",
      " [0.58757485]\n",
      " [0.8510479 ]\n",
      " [0.6511976 ]\n",
      " [0.73652695]\n",
      " [0.73053892]\n",
      " [0.64071856]\n",
      " [0.52095808]\n",
      " [0.58982036]\n",
      " [0.69760479]\n",
      " [0.74550898]\n",
      " [0.59730539]\n",
      " [0.55239521]\n",
      " [0.58233533]\n",
      " [0.73952096]\n",
      " [0.66916168]\n",
      " [0.7994012 ]\n",
      " [0.75748503]\n",
      " [0.5988024 ]\n",
      " [0.63473054]\n",
      " [0.67065868]\n",
      " [0.71182635]\n",
      " [0.74326347]\n",
      " [0.62874251]\n",
      " [0.66766467]\n",
      " [0.63997006]\n",
      " [0.45284431]\n",
      " [0.64296407]\n",
      " [0.56362275]\n",
      " [0.63473054]\n",
      " [0.53068862]\n",
      " [0.57335329]\n",
      " [0.62050898]\n",
      " [0.71856287]\n",
      " [0.55389222]\n",
      " [0.7245509 ]\n",
      " [0.64296407]\n",
      " [0.78742515]\n",
      " [0.5755988 ]\n",
      " [0.58158683]\n",
      " [0.63098802]\n",
      " [0.65269461]\n",
      " [0.67065868]\n",
      " [0.69535928]\n",
      " [0.63398204]\n",
      " [0.45808383]\n",
      " [0.57035928]\n",
      " [0.66317365]\n",
      " [0.58682635]\n",
      " [0.69760479]\n",
      " [0.58233533]\n",
      " [0.72005988]\n",
      " [0.7245509 ]\n",
      " [0.61976048]\n",
      " [0.75973054]\n",
      " [0.85628743]\n",
      " [0.6497006 ]\n",
      " [0.68338323]\n",
      " [0.69760479]\n",
      " [0.70284431]\n",
      " [0.67664671]\n",
      " [0.77020958]\n",
      " [0.61377246]\n",
      " [0.69161677]\n",
      " [0.73652695]\n",
      " [0.76571856]\n",
      " [0.6998503 ]\n",
      " [0.59431138]\n",
      " [0.57784431]\n",
      " [0.72155689]\n",
      " [0.55688623]\n",
      " [0.31062874]\n",
      " [0.75523952]\n",
      " [0.62125749]\n",
      " [0.66017964]\n",
      " [0.73128743]\n",
      " [0.61002994]\n",
      " [0.70658683]\n",
      " [0.58158683]\n",
      " [0.64520958]\n",
      " [0.59356287]\n",
      " [0.64371257]\n",
      " [0.74550898]\n",
      " [0.50823353]\n",
      " [0.66766467]\n",
      " [0.49700599]\n",
      " [0.71706587]\n",
      " [0.68488024]\n",
      " [0.70359281]\n",
      " [0.59805389]\n",
      " [0.67290419]\n",
      " [0.58308383]\n",
      " [0.86077844]\n",
      " [0.64670659]\n",
      " [0.75149701]\n",
      " [0.64595808]\n",
      " [0.64221557]\n",
      " [0.6489521 ]\n",
      " [0.6489521 ]\n",
      " [0.74700599]\n",
      " [0.7238024 ]\n",
      " [0.6489521 ]\n",
      " [0.63622754]\n",
      " [0.68787425]\n",
      " [0.80314371]\n",
      " [0.64371257]\n",
      " [0.65269461]\n",
      " [0.64670659]\n",
      " [0.75973054]\n",
      " [0.67739521]\n",
      " [0.63997006]\n",
      " [0.53967066]\n",
      " [0.67365269]\n",
      " [0.54116766]\n",
      " [0.66991018]\n",
      " [0.57335329]\n",
      " [0.63997006]\n",
      " [0.64670659]\n",
      " [0.54266467]\n",
      " [0.64820359]\n",
      " [0.77320359]\n",
      " [0.5508982 ]\n",
      " [0.66541916]\n",
      " [0.57110778]\n",
      " [0.59056886]\n",
      " [0.67290419]\n",
      " [0.71107784]\n",
      " [0.55314371]\n",
      " [0.75224551]\n",
      " [0.66317365]\n",
      " [0.60778443]\n",
      " [0.60179641]\n",
      " [0.52694611]\n",
      " [0.65494012]\n",
      " [0.72005988]\n",
      " [0.81137725]\n",
      " [0.58383234]\n",
      " [0.56287425]\n",
      " [0.60329341]\n",
      " [0.61826347]\n",
      " [0.74625749]\n",
      " [0.5741018 ]\n",
      " [0.73353293]\n",
      " [0.6242515 ]\n",
      " [0.64371257]\n",
      " [0.72904192]\n",
      " [0.72979042]\n",
      " [0.61452096]\n",
      " [0.69685629]\n",
      " [0.57634731]\n",
      " [0.52020958]\n",
      " [0.71706587]\n",
      " [0.54266467]\n",
      " [0.56137725]\n",
      " [0.88772455]\n",
      " [0.77170659]\n",
      " [0.70508982]\n",
      " [0.61901198]\n",
      " [0.74251497]\n",
      " [0.76646707]\n",
      " [0.66167665]\n",
      " [0.74251497]\n",
      " [0.6998503 ]\n",
      " [0.58233533]\n",
      " [0.61676647]\n",
      " [0.73053892]\n",
      " [0.74401198]\n",
      " [0.58532934]\n",
      " [0.68038922]\n",
      " [0.69236527]\n",
      " [0.66841317]\n",
      " [0.64146707]\n",
      " [0.66691617]\n",
      " [0.62949102]\n",
      " [0.66092814]\n",
      " [0.61976048]\n",
      " [0.66242515]\n",
      " [0.625     ]\n",
      " [0.58907186]\n",
      " [0.70733533]\n",
      " [0.65868263]\n",
      " [0.76347305]\n",
      " [0.5988024 ]\n",
      " [0.79865269]\n",
      " [0.64446108]\n",
      " [0.72829341]\n",
      " [0.63098802]\n",
      " [0.69236527]\n",
      " [0.60778443]\n",
      " [0.58083832]\n",
      " [0.72679641]\n",
      " [0.73652695]\n",
      " [0.63847305]\n",
      " [0.65419162]\n",
      " [0.61227545]\n",
      " [0.68188623]\n",
      " [0.63547904]\n",
      " [0.58682635]\n",
      " [0.68263473]\n",
      " [0.67065868]\n",
      " [0.62874251]\n",
      " [0.56886228]\n",
      " [0.67964072]\n",
      " [0.52170659]\n",
      " [0.72829341]\n",
      " [0.62874251]\n",
      " [0.47155689]\n",
      " [0.65793413]\n",
      " [0.70209581]\n",
      " [0.59206587]\n",
      " [0.71182635]\n",
      " [0.72155689]\n",
      " [0.74625749]\n",
      " [0.60553892]\n",
      " [0.68712575]\n",
      " [0.68263473]\n",
      " [0.61077844]\n",
      " [0.7754491 ]\n",
      " [0.71257485]\n",
      " [0.66991018]\n",
      " [0.65419162]\n",
      " [0.50523952]\n",
      " [0.63473054]\n",
      " [0.68712575]\n",
      " [0.64595808]\n",
      " [0.70583832]\n",
      " [0.73053892]\n",
      " [0.64670659]\n",
      " [0.6504491 ]\n",
      " [0.65568862]\n",
      " [0.64595808]\n",
      " [0.67290419]\n",
      " [0.58458084]\n",
      " [0.62949102]\n",
      " [0.65344311]\n",
      " [0.59730539]\n",
      " [0.68787425]\n",
      " [0.69011976]\n",
      " [0.70508982]\n",
      " [0.65868263]\n",
      " [0.58982036]\n",
      " [0.4745509 ]\n",
      " [0.63323353]\n",
      " [0.61526946]\n",
      " [0.58383234]\n",
      " [0.64670659]\n",
      " [0.78143713]\n",
      " [0.62275449]\n",
      " [0.61077844]\n",
      " [0.67664671]\n",
      " [0.56212575]\n",
      " [0.49401198]\n",
      " [0.68038922]\n",
      " [0.54191617]\n",
      " [0.70583832]\n",
      " [0.62874251]\n",
      " [0.71482036]\n",
      " [0.68862275]\n",
      " [0.77095808]\n",
      " [0.49850299]\n",
      " [0.72080838]\n",
      " [0.6242515 ]\n",
      " [0.56586826]\n",
      " [0.66392216]\n",
      " [0.63323353]\n",
      " [0.53068862]\n",
      " [0.53443114]\n",
      " [0.52694611]\n",
      " [0.6758982 ]\n",
      " [0.70359281]\n",
      " [0.76422156]\n",
      " [0.72230539]\n",
      " [0.50299401]\n",
      " [0.6758982 ]\n",
      " [0.66766467]\n",
      " [0.71032934]\n",
      " [0.55763473]\n",
      " [0.59056886]\n",
      " [0.58233533]\n",
      " [0.72305389]\n",
      " [0.64221557]\n",
      " [0.6489521 ]\n",
      " [0.67664671]\n",
      " [0.74476048]\n",
      " [0.59805389]\n",
      " [0.67889222]\n",
      " [0.61976048]\n",
      " [0.65643713]\n",
      " [0.60553892]\n",
      " [0.66841317]\n",
      " [0.72230539]\n",
      " [0.58383234]\n",
      " [0.54116766]\n",
      " [0.57260479]\n",
      " [0.75748503]\n",
      " [0.64446108]\n",
      " [0.88248503]\n",
      " [0.59356287]\n",
      " [0.63323353]]\n",
      "y_test: [[0.06437768]\n",
      " [1.        ]\n",
      " [0.54077253]\n",
      " [0.91845494]\n",
      " [0.        ]\n",
      " [0.27038627]\n",
      " [0.75107296]]\n"
     ]
    }
   ],
   "source": [
    "print('After normalization:')\n",
    "print('x_train:',x_train)\n",
    "print('x_test:',x_test)\n",
    "print('y_train:',y_train)\n",
    "print('y_test:',y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start to realize the BP neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the nonlinear transformation and their deravatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def tanh_deriv(x):\n",
    "    return 1.0 - np.tanh(x)*np.tanh(x)\n",
    "def logistic(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "def logistic_derivative(x):\n",
    "    return logistic(x)*(1-logistic(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the neutral network with BP algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, activation='tanh'):\n",
    "        #Param layers is list containing the number of units in each layer and it should be at least two values.\n",
    "        #Param activation is the activation function to be used.\n",
    "        if activation == 'logistic':\n",
    "            self.activation = logistic\n",
    "            self.activation_deriv = logistic_derivative\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = tanh\n",
    "            self.activation_deriv = tanh_deriv\n",
    "            \n",
    "        self.weights = []\n",
    "       \n",
    "        #The cycle starts from 1, which is equivalent to the initialization of weights based on the second level.\n",
    "        for i in range(1, len(layers) - 1): \n",
    "            #The  assignments of the current neural nodes\n",
    "            np.random.seed(8)\n",
    "            self.weights.append((2*np.random.random((layers[i - 1] + 1, layers[i] + 1))-1)*0.25)\n",
    "            \n",
    "            np.random.seed(11)\n",
    "            self.weights.append((2*np.random.random((layers[i] + 1, layers[i + 1]))-1)*0.25)\n",
    "    \n",
    "    #Define the training process with BP algorithm\n",
    "    def fit(self, X, y, learning_rate=0.2, epochs=10000):\n",
    "        X = np.atleast_2d(X)\n",
    "        temp = np.ones([X.shape[0], X.shape[1]+1])\n",
    "        temp[:, 0:-1] = X\n",
    "        X = temp\n",
    "        y = np.array(y)\n",
    " \n",
    "        for k in range(epochs):\n",
    "            i = np.random.randint(X.shape[0])\n",
    "            a = [X[i]]\n",
    " \n",
    "            for l in range(len(self.weights)):\n",
    "                a.append(self.activation(np.dot(a[l], self.weights[l])))\n",
    "            error = y[i] - a[-1]\n",
    "            deltas = [error * self.activation_deriv(a[-1])]\n",
    " \n",
    "            for l in range(len(a) - 2, 0, -1):\n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_deriv(a[l]))\n",
    "            deltas.reverse()\n",
    " \n",
    "            for i in range(len(self.weights)):\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)        \n",
    "            \n",
    "    #Define the forecast function\n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        temp = np.ones(x.shape[0]+1)\n",
    "        temp[0:-1] = x\n",
    "        a = temp\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        return a     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the number of neuron in the input layer P equal the number of structure variable, which is 5. And set the number of neuron in the output layer O as 1. As for the number of neurons in the hidden layer, we use the emprical formula as below，resulting in 5."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P=5\n",
    "O=t\n",
    "n=4\n",
    "L=int(sqrt(P*(O+3))+1)-n\n",
    "learning_rate=0.0001\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork([P,L,O], 'tanh')\n",
    "X = x_train\n",
    "y = y_train\n",
    "nn.fit(X,y,learning_rate,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31948021],\n",
       "       [0.45967042],\n",
       "       [0.40295619],\n",
       "       [0.40949805],\n",
       "       [0.3463283 ],\n",
       "       [0.39813533],\n",
       "       [0.43627277]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict=[]\n",
    "y_predict.append(nn.predict(x_test[0]))\n",
    "y_predict=np.array(y_predict).T\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05900000e+02,  4.66249525e+00, -8.78055543e-02,\n",
       "         4.57831861e+00]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=np.zeros(shape=(t+1,4))\n",
    "ANN=min_max_scaler.inverse_transform(y_predict)\n",
    "prediction[1:,2]=np.hstack((ANN))\n",
    "prediction[:,0]=JPY.iloc[-(t+1):,0].values\n",
    "prediction[:,1]=np.log(JPY.iloc[-(t+1):,0].values)\n",
    "prediction[0,1]\n",
    "prediction[1,3]=prediction[0,1]+prediction[1,2]\n",
    "prediction[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (2,t+1):\n",
    "    prediction[i,3]=prediction[i,2]+ prediction[i-1,3]\n",
    "prediction[1:,3]=np.e**(prediction[1:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('prediction_ANN.csv',prediction,delimiter=',',\n",
    "           header='et,lnet,ANN,et_ANN',fmt='%6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cauculate the accurancy by MAE, MSE, RMSE,MAPE and A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># et</th>\n",
       "      <th>lnet</th>\n",
       "      <th>ANN</th>\n",
       "      <th>et_ANN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106.285</td>\n",
       "      <td>4.666124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.900</td>\n",
       "      <td>4.662495</td>\n",
       "      <td>-0.087806</td>\n",
       "      <td>97.350572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106.605</td>\n",
       "      <td>4.669130</td>\n",
       "      <td>0.075516</td>\n",
       "      <td>104.986803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.775</td>\n",
       "      <td>4.670724</td>\n",
       "      <td>0.009444</td>\n",
       "      <td>105.982991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>107.385</td>\n",
       "      <td>4.676421</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>107.807135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106.925</td>\n",
       "      <td>4.672128</td>\n",
       "      <td>-0.056528</td>\n",
       "      <td>101.882105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>106.780</td>\n",
       "      <td>4.670771</td>\n",
       "      <td>0.003828</td>\n",
       "      <td>102.272821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      # et      lnet       ANN      et_ANN\n",
       "0  106.285  4.666124  0.000000    0.000000\n",
       "1  105.900  4.662495 -0.087806   97.350572\n",
       "2  106.605  4.669130  0.075516  104.986803\n",
       "3  106.775  4.670724  0.009444  105.982991\n",
       "4  107.385  4.676421  0.017065  107.807135\n",
       "5  106.925  4.672128 -0.056528  101.882105\n",
       "6  106.780  4.670771  0.003828  102.272821"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=pd.read_csv('prediction_ANN.csv',sep=',')\n",
    "prediction.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([105.9  , 106.605, 106.775, 107.385, 106.925, 106.78 , 107.195])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_real=prediction.iloc[1:,0].values\n",
    "y_pre_ANN=prediction.iloc[1:,3].values\n",
    "y_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.009450000000001"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean squrad error\n",
    "MSE_ANN=np.sum(np.abs(y_real-y_pre_ANN))/t\n",
    "MSE_ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.468606823087722"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mean abosolute error\n",
    "MAE_ANN=np.sum((y_real-y_pre_ANN)*(y_real-y_pre_ANN))/t\n",
    "MAE_ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7347766426834323"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RMSE\n",
    "RMSE_ANN=np.sqrt(MSE_ANN)\n",
    "RMSE_ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028269271956839842"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MAPE\n",
    "MAPE_ANN=1/t*np.sum(np.abs((y_real-y_pre_ANN)/y_real))\n",
    "MAPE_ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9717307280431602"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#U\n",
    "U_ANN=1-MAPE_ANN\n",
    "U_ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index=np.zeros(shape=(1,5))\n",
    "index[[0]]=[MSE_ANN,MAE_ANN,RMSE_ANN,MAPE_ANN,U_ANN]\n",
    "\n",
    "np.savetxt('index_ANN.csv',index,delimiter=',',header='MSE,MAE,RMSE,MAPE,U',fmt='%6f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Use the grid search method to adjust the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best ANN score:0.9717307\n",
      "Best ANN parameters:{'n': 4, 'learning_rate': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "## This Grid search take about 3 minutes.##\n",
    "best_U_ANN=0\n",
    "for learning_rate in [0.0001,0.0005,0.001,0.005,0.01,0.05,0.1]:\n",
    "    for n in [0,1,2,3,4,5,6,7]:\n",
    "        L=int(sqrt(P*(O+3))+1)-n\n",
    "        nn = NeuralNetwork([P,L,O], 'tanh')\n",
    "        X = x_train\n",
    "        y = y_train\n",
    "        nn.fit(X,y,learning_rate,10000)\n",
    "        \n",
    "        y_predict=[]\n",
    "        y_predict.append(nn.predict(x_test[0]))\n",
    "        y_predict=np.array(y_predict).T\n",
    "       \n",
    "        prediction=np.zeros(shape=(t+1,4))\n",
    "        ANN=min_max_scaler.inverse_transform(y_predict)\n",
    "        prediction[1:,2]=np.hstack((ANN))\n",
    "        prediction[:,0]=JPY.iloc[-(t+1):,0].values\n",
    "        prediction[:,1]=np.log(JPY.iloc[-(t+1):,0].values)\n",
    "        prediction[1,3]=prediction[0,1]+prediction[1,2]\n",
    "        \n",
    "        for i in range (2,t+1):\n",
    "            prediction[i,3]=prediction[i,2]+ prediction[i-1,3]\n",
    "        prediction[1:,3]=np.e**(prediction[1:,3])        \n",
    "        \n",
    "        y_real=prediction[1:,0]\n",
    "        y_pre_ANN=prediction[1:,3]\n",
    "        \n",
    "        MAPE_ANN=1/t*np.sum(np.abs((y_real-y_pre_ANN)/y_real))\n",
    "        U_ANN=1-MAPE_ANN\n",
    "        \n",
    "        if U_ANN > best_U_ANN:\n",
    "            best_U_ANN=U_ANN\n",
    "            best_ANN_parameters = {'n':n,'learning_rate':learning_rate}\n",
    "            \n",
    "print(\"Best ANN score:{:.7f}\".format(best_U_ANN))\n",
    "print(\"Best ANN parameters:{}\".format(best_ANN_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
